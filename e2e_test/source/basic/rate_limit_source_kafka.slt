############## Create kafka seed data

statement ok
create table kafka_seed_data (v1 int);

statement ok
insert into kafka_seed_data select * from generate_series(1, 1000);

############## Sink into kafka

statement ok
create sink kafka_sink
from
  kafka_seed_data with (
    allow.auto.create.topics = true,
    properties.bootstrap.server = 'message_queue:29092',
    topic = 'rate_limit_source_kafka_0',
    type = 'append-only',
    force_append_only='true',
    connector = 'kafka'
);

# Make sure that records are flushed.
statement ok
flush;

############## Source from kafka (rate_limit = 0)

# Wait for topic to be created
skipif in-memory
sleep 3s

statement ok
create source kafka_source (v1 int) with (
  connector = 'kafka',
  topic = 'rate_limit_source_kafka_0',
  properties.bootstrap.server = 'message_queue:29092',
  scan.startup.mode = 'earliest',
  streaming_rate_limit = 0
) FORMAT PLAIN ENCODE JSON

statement ok
flush;

############## Check data

skipif in-memory
sleep 3s

############## Create MV on source

statement ok
create materialized view mv1 as select count(*) from kafka_source;

# Demonstrate that mv2's source read still depends on the rate_limit of the source.

statement ok
SET STREAMING_RATE_LIMIT=default;

statement ok
create materialized view mv2 as select count(*) from kafka_source;

statement ok
SET STREAMING_RATE_LIMIT=0;

statement ok
create materialized view mv3 as select count(*) from kafka_source;

############## MVs should have 0 records, since source has (rate_limit = 0)

statement ok
flush;

query I
select * from mv1;
----
0

query I
select * from mv2;
----
0

query I
select * from mv3;
----
0

############## Cleanup

statement ok
drop materialized view mv1;

statement ok
drop materialized view mv2;

statement ok
drop materialized view mv3;

statement ok
drop source kafka_source;

statement ok
drop sink kafka_sink;

statement ok
drop table kafka_seed_data;